# Emission Model

## Dependencies

* Python 3
* Pytorch

## Data processes
Two ways for filtering the data are explored

### Use IQR to filter the data
Interquartile range (IQR) is a method that always be used with box plot to find outliers. The method could be run for several iterations to get rid of the outliers totally (Since after each iteration, the statistic features will be calculated again for the remaining data, new “outliers” may come up). And the box images and data amounts before and after filtering are shown below.

Before filtering

![](image/image1.png)

After filtering

![](image/image2.png)

|    | Original | Filtered
|:------------------------ | :------------------------ | :-------------------------
|HCaltitude |   339   |   204
|HCDOE |   2960   |   1786
|HCTPA |   591   |   495
|**Total** |   **3890**   |   **2495**

### Filter by “xHCOcI” column
Since the amount of data left after filtered by IQR decreased a lot, another way is to set threshold. Since `xHCOcI` is the target column, we combined the three datasets and set the threshold as 200 after visualization. Then 1 data point and 162 data points were taken away from altitude and DOE respectively. The threshold as well as data amounts comparison is shown below.

![](image/image3.png)

|    | Original | Filtered
|:------------------------ | :------------------------ | :-------------------------
|HCaltitude |   339   |   338
|HCDOE |   2960   |   2798
|HCTPA |   591   |   591
|**Total** |   **3890**   |   **3727**

### Scale
All data are scaled to [0,1] using `MinMaxScalar`. Other scalers like `MaxABsScaler` or `Standardization` don't work on this data.

You can use one `#` all the way up to `######` six for different heading sizes.

If you'd like to quote someone, use the > character before the line:

## Network Architecture
* L1
    * nn.Linear(self.features=13, 512),
    * nn.LeakyReLU(0.2),
* L2
    * nn.Linear(512, 1024),
    * nn.LeakyReLU(0.2),
            
* L3
    * nn.Linear(1024, 256),
    * nn.LeakyReLU(0.2),
* L4
    * nn.Linear(256, 1),

## Network Architecture
Networks with same structures are trained with:
1. Only DOE data
2. Only TPA data
3. Both DOE data and TPA data with meta learning algorithm
Data are split as 70% for training and 30% for test

Since the mean value of the three kinds of data varies a lot, to make the model perform well on all kinds of data, the loss for all the three experiments are set as:

Loss_total = (MSELoss on DOE)/(mean value of DOE) + (MSELoss on TPA)/(mean value of TPA) + (MSELoss on altitude)/(mean value of altitude)

And We stored the weight with the least loss for each experiment.

## Results on test set 
### Only filtered by “xHCOcI” column
The two tales show R2 score and RMSE error tested on test sets. The headers of rows are the names of training sets while the headers of columns refer to the test sets.

| DOE | TPA | altitude
:------------------------ | :------------------------ | :-------------------------
DOE | 0.81 | -0.75 | -0.42
TPA | 0.25 | 0.80 | 0.20
DOE and TPA + Meta | 0.47 | 0.15 | 0.31

| DOE | TPA | altitude
:------------------------ | :------------------------ | :-------------------------
DOE | 16.66 | 12.49 | 24.85
TPA | 32.44 | 4.26 | 18.66
DOE and TPA + Meta | 25.45 | 8.83 | 17.34

The visualization results are shown below.
![](image/without_IQR1.png)
![](image/without_IQR2.png)

### Filtered with IQR
Results with same formats as the former one are shown below

| DOE | TPA | altitude
:------------------------ | :------------------------ | :-------------------------
DOE | 0.78 | -0.26 | -0.12
TPA | 0.43 | 0.80 | 0.51
DOE and TPA + Meta | 0.56 | 0.54 | 0.41

| DOE | TPA | altitude
:------------------------ | :------------------------ | :-------------------------
DOE | 9,03 | 9.44 | 11.36
TPA | 14.04 | 4.09 | 7.51
DOE and TPA + Meta | 12.71 | 6.05 | 8.23

The visualization results are shown below.
![](image/with_IQR1.png)
![](image/with_IQR2.png)
